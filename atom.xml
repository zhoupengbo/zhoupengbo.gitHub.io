<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>漫泊今生 扶垚而上</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-02-16T05:02:07.168Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>zhou.pengbo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Apache Kylin 1.0中的混合模型</title>
    <link href="http://yoursite.com/2020/02/05/Apache-Kylin-1.0%E4%B8%AD%E7%9A%84%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/02/05/Apache-Kylin-1.0%E4%B8%AD%E7%9A%84%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-02-05T12:36:20.000Z</published>
    <updated>2020-02-16T05:02:07.168Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Kylin v1.0引入了一个新的实现“混合模型”（也称为“动态模型”）; 这篇文章介绍了这个概念以及如何创建一个混合实例。</p><a id="more"></a><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>对于传入的SQL查询，Kylin选择一个（并且只有一个）实现来提供查询; 在“混合”之前，只有一种类型的实现向用户开放：Cube。也就是说，只有1个Cube被选中来回答查询;</p><p>现在我们来看一个示例案例。假设用户有一个名为“Cube_V1”的多维数据集，它已经建立了几个月; 现在，用户希望添加新的维度或指标以满足其业务需求; 于是他创建了一个名为“Cube_V2”的新立方体;</p><p>由于某些原因用户想要保留“Cube_V1”，并且期望从“Cube_V1”的结束日期开始构建“Cube_V2”; 可能的原因包括：</p><ul><li>历史源数据已从Hadoop中删除，从一开始就无法构建“Cube_V2”;</li><li>立方体很大，重建需要很长时间;</li><li>新维度/指标仅在某一天有效或应用;</li><li>当查询使用新的维度/指标时，用户感觉过去的结果为空。</li></ul><p>对于针对通用维度/指标的查询，用户期望扫描“Cube_V1”和“Cube_V2”以获得完整的结果集; 在这样的背景下，引入“混合模型”来解决这个问题。</p><h3 id="混合模型"><a href="#混合模型" class="headerlink" title="混合模型"></a>混合模型</h3><p>混合模型是一个新的实现，它是一个或多个其他实现（立方体）的组合; 见下图。</p><p><img src="http://upload-images.jianshu.io/upload_images/7875120-0d6377c5e4ed0ce9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p><p>混合模型没有其真正的存储空间; 它就像在表格上的虚拟数据库视图一样; 混合实例充当委托者，将请求转发给其子实现，然后在从实例返回时合并结果。</p><h3 id="如何添加混合实例"><a href="#如何添加混合实例" class="headerlink" title="如何添加混合实例"></a>如何添加混合实例</h3><p>到目前为止，没有用于创建/编辑混合模型的UI界面; 如果有需要，您需要手动编辑Kylin元数据;</p><h4 id="第1步：做一个kylin元数据存储的备份"><a href="#第1步：做一个kylin元数据存储的备份" class="headerlink" title="第1步：做一个kylin元数据存储的备份"></a>第1步：做一个kylin元数据存储的备份</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export KYLIN_HOME&#x3D;&quot;&#x2F;path&#x2F;to&#x2F;kylin&quot;</span><br><span class="line"></span><br><span class="line">$KYLIN_HOME&#x2F;bin&#x2F;metastore.sh backup</span><br></pre></td></tr></table></figure><p>这将创建一个备份文件夹，假定它是$ KYLIN_HOME / metadata_backup / 2015-09-25 /</p><h4 id="第2步：创建子文件夹“hybrid”"><a href="#第2步：创建子文件夹“hybrid”" class="headerlink" title="第2步：创建子文件夹“hybrid”"></a>第2步：创建子文件夹“hybrid”</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $KYLIN_HOME&#x2F;metadata_backup&#x2F;2015-09-25&#x2F;hybrid</span><br></pre></td></tr></table></figure><h4 id="第3步：创建混合实例json文件"><a href="#第3步：创建混合实例json文件" class="headerlink" title="第3步：创建混合实例json文件"></a>第3步：创建混合实例json文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi $KYLIN_HOME&#x2F;metadata_backup&#x2F;2015-09-25&#x2F;hybrid&#x2F;my_hybrid.json</span><br></pre></td></tr></table></figure><p>像下面这样的输入内容，“名称”和“uuid”需要是唯一的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;uuid&quot;: &quot;9iiu8590-64b6-4367-8fb5-7500eb95fd9c&quot;,</span><br><span class="line">  &quot;name&quot;: &quot;my_hybrid&quot;,</span><br><span class="line">  &quot;realizations&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">           &quot;type&quot;: &quot;CUBE&quot;,</span><br><span class="line">           &quot;realization&quot;: &quot;Cube_V1&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">            &quot;type&quot;: &quot;CUBE&quot;,</span><br><span class="line">            &quot;realization&quot;: &quot;Cube_V2&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里“Cube_V1”和“Cube_V2”是你想合并的Cube名称。</p><h4 id="第4步：将混合实例添加到项目"><a href="#第4步：将混合实例添加到项目" class="headerlink" title="第4步：将混合实例添加到项目"></a>第4步：将混合实例添加到项目</h4><p>使用文本编辑器打开项目json文件（例如项目“default”）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi $KYLIN_HOME&#x2F;metadata_backup&#x2F;2015-09-25&#x2F;project&#x2F;default.json</span><br></pre></td></tr></table></figure><p>在“realizations”数组中，添加一个如下所示的条目，类型需要是“HYBRID”，“实现”是混合实例的名称：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;my_hybrid&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;HYBRID&quot;,</span><br><span class="line">  &quot;realization&quot;: &quot;my_hybrid&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="第5步：上传元数据"><a href="#第5步：上传元数据" class="headerlink" title="第5步：上传元数据"></a>第5步：上传元数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$KYLIN_HOME&#x2F;bin&#x2F;metastore.sh restore $KYLIN_HOME&#x2F;metadata_backup&#x2F;2015-09-25&#x2F;</span><br></pre></td></tr></table></figure><p>请注意，“restore”操作会将元数据从本地上传到远程hbase store，这可能会覆盖远程中的更改; 因此，请在此期间没有从Kylin服务器更改元数据（无 build job，无Cube 创建/更新等）时执行此操作，或者在运行“restore”之前仅将已更改的文件提取到空的本地文件夹。</p><h4 id="第6步：重新加载元数据"><a href="#第6步：重新加载元数据" class="headerlink" title="第6步：重新加载元数据"></a>第6步：重新加载元数据</h4><p>重新启动Kylin服务器，或在Kylin Web UI的“管理”标签中点击“重新加载元数据”以加载更改; 理想情况下，混合动力车将开始工作; 你可以通过编写一些SQL来做一些验证。</p><h3 id="常问问题"><a href="#常问问题" class="headerlink" title="常问问题"></a>常问问题</h3><p><strong>问题1</strong>：混合模型何时被调用来回答客户端SQL查询？<br>如果混合模型中存在一个立方体可以回答查询，则将选择混合体;</p><p><strong>问题2</strong>：混合模型如何回答一个查询？<br>Hybrid将把查询委托给它的每个子实现; 如果一个子多维数据集能够执行此查询（匹配所有维度/指标），它会将结果返回到混合模式，否则将被跳过; 最后，查询引擎会在返回给用户之前聚合来自混合的数据;</p><p><strong>问题3</strong>：混合模型检查日期/时间重复吗？<br>不检查; 这个需要用户确保混合中的立方体不具有重复的日期/时间范围; 例如，“Cube_V1”在2015-9-20（不含）结束，“Cube_V2”应从2015-9-20（含）开始;</p><p><strong>问题4</strong>：混合模型会限制具有相同数据模型的子立方体吗？<br>不会; 为了提供灵活性，Hybrid不检查子立方体的事实表/查找表和连接条件是否相同; 但用户应该明白他们在做什么以避免意外的行为。</p><p><strong>问题5</strong>：混合模型中是否可以包含子hybrid ？<br>不能; 没有这个必要; 到目前为止，假设所有的Child都是Cube;</p><p><strong>问题6</strong>：我可以使用混合加入多个立方体吗？<br>不能; 混合模型的目的是连接历史Cube和新Cube，类似“union”而不是“join”;</p><p><strong>问题7</strong>：如果子立方体被禁用，它是否会通过混合动力进行扫描？<br>不会; 混合实例会在发送查询之前检查子实现的状态; 所以如果立方体被禁用，它将不会被扫描。</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p><strong>1.</strong> 必须在构建好新的cube后备份元数据，从而进行修改恢复<br><strong>2.</strong> 修改完元数据后必须重启kylin集群或者重新载入元数据，否则报错（Overwriting conflict /project/<strong><em>.json, expect old TS 1525758479256, but it is 152576031000）<br>*</em>3.</strong> 若修改视图表（如添加字段），修改完毕后要reload一下<br><strong>4.</strong> Purge Cube 后Hbase中存储的计算结果不会被删除，Hbase可查<br><strong>5.</strong> 新Cube不能build旧Cube已经build过的相同日期的数据，若修复历史数据，需先删除旧的Segment<br><strong>6.</strong> 若想修改字段名，必须Perge Cube，Hybrid 无法满足需求<br><strong>7.</strong> 新增字段在build完毕后Kylin表才会更新字段信息</p><h3 id="清除Hbase无用数据表"><a href="#清除Hbase无用数据表" class="headerlink" title="清除Hbase无用数据表"></a>清除Hbase无用数据表</h3><p>当我们对cube执行purge/drop/merge时，一些HBase的表可能会保留在HBase中，而这些表不再被查询，尽管Kylin会做一些自动的垃圾回收，但是它可能不会覆盖所有方面，所以需要我们能够每隔一段时间做一些离线存储的清理工作。具体步骤如下：</p><p><strong>1.</strong> 检查哪些资源需要被清理，这个操作不会删除任何内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;KYLIN_HOME&#125;&#x2F;bin&#x2F;kylin.sh org.apache.kylin.storage.hbase.util.StorageCleanupJob --delete false</span><br></pre></td></tr></table></figure><p><strong>2.</strong> 根据上面的输出结果，挑选一两个资源看看是否是不再需要的。接着，在上面的命令基础上添加“–delete true”选项，开始执行清理操作，命令执行完成后，中间的HDFS文和盒HTables表就被删除了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Kylin v1.0引入了一个新的实现“混合模型”（也称为“动态模型”）; 这篇文章介绍了这个概念以及如何创建一个混合实例。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kylin" scheme="http://yoursite.com/categories/Kylin/"/>
    
    
      <category term="Kylin" scheme="http://yoursite.com/tags/Kylin/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="2020" scheme="http://yoursite.com/tags/2020/"/>
    
  </entry>
  
  <entry>
    <title>基于HBase构建千亿级文本数据相似度计算与快速去重系统</title>
    <link href="http://yoursite.com/2020/02/05/%E5%9F%BA%E4%BA%8EHBase%E6%9E%84%E5%BB%BA%E5%8D%83%E4%BA%BF%E7%BA%A7%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%BF%AB%E9%80%9F%E5%8E%BB%E9%87%8D%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2020/02/05/%E5%9F%BA%E4%BA%8EHBase%E6%9E%84%E5%BB%BA%E5%8D%83%E4%BA%BF%E7%BA%A7%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%BF%AB%E9%80%9F%E5%8E%BB%E9%87%8D%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-02-05T12:34:40.000Z</published>
    <updated>2020-02-16T04:31:33.701Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>随着大数据时代的到来，数据信息在给我们生活带来便利的同时，同样也给我们带来了一系列的考验与挑战。本文主要介绍了基于 Apache HBase 与 Google SimHash 等多种算法共同实现的一套支持百亿级文本数据相似度计算与快速去重系统的设计与实现。该方案在公司业务层面彻底解决了多主题海量文本数据所面临的存储与计算慢的问题。</p><a id="more"></a><h3 id="一-面临的问题"><a href="#一-面临的问题" class="headerlink" title="一. 面临的问题"></a>一. 面临的问题</h3><h4 id="1-如何选择文本的相似度计算或去重算法？"><a href="#1-如何选择文本的相似度计算或去重算法？" class="headerlink" title="1. 如何选择文本的相似度计算或去重算法？"></a>1. 如何选择文本的相似度计算或去重算法？</h4><p>常见的有余弦夹角算法、欧式距离、Jaccard 相似度、最长公共子串、编辑距离等。这些算法对于待比较的文本数据不多时还比较好用，但在海量数据背景下，如果每天产生的数据以千万计算，我们如何对于这些海量千万级的数据进行高效的合并去重和相似度计算呢？</p><h4 id="2-如何实现快速计算文本相似度或去重呢？"><a href="#2-如何实现快速计算文本相似度或去重呢？" class="headerlink" title="2. 如何实现快速计算文本相似度或去重呢？"></a>2. 如何实现快速计算文本相似度或去重呢？</h4><p>如果我们选好了相似度计算和去重的相关算法，那我们怎么去做呢？如果待比较的文本数据少，我们简单遍历所有文本进行比较即可，那对于巨大的数据集我们该怎么办呢？遍历很明显是不可取的。</p><h4 id="3-海量数据的存储与快速读写"><a href="#3-海量数据的存储与快速读写" class="headerlink" title="3. 海量数据的存储与快速读写"></a>3. 海量数据的存储与快速读写</h4><h3 id="二-SimHash-算法引入"><a href="#二-SimHash-算法引入" class="headerlink" title="二. SimHash 算法引入"></a>二. SimHash 算法引入</h3><p>基于问题一，我们引入了 SimHash 算法来实现海量文本的相似度计算与快速去重。下面我们简单了解下该算法。</p><h4 id="1-局部敏感哈希"><a href="#1-局部敏感哈希" class="headerlink" title="1. 局部敏感哈希"></a>1. 局部敏感哈希</h4><p>在介绍 SimHash 算法之前，我们先简单介绍下局部敏感哈希是什么。局部敏感哈希的基本思想类似于一种空间域转换思想，LSH 算法基于一个假设，如果两个文本在原有的数据空间是相似的，那么分别经过哈希函数转换以后的它们也具有很高的相似度；相反，如果它们本身是不相似的，那么经过转换后它们应仍不具有相似性。</p><p> 局部敏感哈希的最大特点就在于保持数据的相似性，举一个小小的例子说明一下：对A文章微调后我们称其为B文章（可能只是多了一个‘的’字），如果此时我们计算两篇文章的 MD5 值，那么必将大相径庭。而局部敏感哈希的好处是经过哈希函数转换后的值也只是发生了微小的变化，即如果两篇文章相似度很高，那么在算法转换后其相似度也会很高。</p><p>MinHash 与 SimHash 算法都属于局部敏感哈希，一般情况若每个 Feature 无权重，则 MinHash 效果优于 SimHash 有权重时 SimHash 合适。长文本使用 Simhash 效果很好，短文本使用 Simhash 准备度不高。</p><h4 id="2-SimHash-算法"><a href="#2-SimHash-算法" class="headerlink" title="2. SimHash 算法"></a>2. SimHash 算法</h4><p>SimHash 是 Google 在2007年发表的论文《Detecting Near-Duplicates for Web Crawling 》中提到的一种指纹生成算法或者叫指纹提取算法，被 Google 广泛应用在亿级的网页去重的 Job 中，其主要思想是降维，经过simhash降维后，可能仅仅得到一个长度为32或64位的二进制由01组成的字符串。而一维查询则是非常快速的。</p><p>SimHash的工作原理我们这里略过，大家可以简单理解为：我们可以利用SimHash算法为每一个网页/文章生成一个长度为32或64位的二进制由01组成的字符串（向量指纹），形如：1000010010101101111111100000101011010001001111100001001011001011。</p><h4 id="3-海明距离"><a href="#3-海明距离" class="headerlink" title="3. 海明距离"></a>3. 海明距离</h4><p>两个码字的对应比特取值不同的比特数称为这两个码字的海明距离。在一个有效编码集中,任意两个码字的海明距离的最小值称为该编码集的海明距离。举例如下：10101和00110从第一位开始依次有第一位、第四、第五位不同，则海明距离为3。</p><p>在 google 的论文给出的数据中，64位的签名，在海明距离为3的情况下，可认为两篇文档是相似的或者是重复的，当然这个值只是参考值。</p><p>这样，基于 SimHash 算法，我们就可以将百亿千亿级的高维特征文章转变为一维字符串后再通过计算其海明距离判断网页/文章的相似度，可想效率必将大大提高。</p><h3 id="三-效率问题"><a href="#三-效率问题" class="headerlink" title="三. 效率问题"></a>三. 效率问题</h3><p>到这里相似度问题基本解决，但是按这个思路，在海量数据几百亿的数量下，效率问题还是没有解决的，因为数据是不断添加进来的，不可能每来一条数据，都要和全库的数据做一次比较，按照这种思路，处理速度会越来越慢，线性增长。</p><p>这里，我们要引入一个新的概念：<strong>抽屉原理</strong>，也称鸽巢原理。下面我们简单举例说一下：</p><p>桌子上有四个苹果，但只有三个抽屉，如果要将四个苹果放入三个抽屉里，那么必然有一个抽屉中放入了两个苹果。如果每个抽屉代表一个集合，每一个苹果就可以代表一个元素，假如有n+1个元素放到n个集合中去，其中必定有一个集合里至少有两个元素。</p><p>抽屉原理就是这么简单，那如果用它来解决我们海量数据的遍历问题呢？</p><p>针对海量数据的去重效率，我们可以将64位指纹，切分为4份16位的数据块，根据抽屉原理在海明距离为3的情况，如果两个文档相似，那么它必有一个块的数据是相等的。</p><p>那也就是说，我们可以以某文本的 SimHash 的每个16位截断指纹为 Key，Value 为 Key 相等时文本的 SimHash 集合存入 K-V 数据库即可，查询时候，精确匹配这个指纹的4个16位截断指纹所对应的4个 SimHash 集合即可。</p><p>如此，假设样本库，有2^37 条数据（1375亿数据），假设数据均匀分布，则每个16位（16个01数字随机组成的组合为2^16 个）倒排返回的最大数量为<br>(2^37) * 4 / (2^16) =8388608个候选结果，4个16位截断索引，总的结果为：4*8388608=33554432，约为3356万，通过<br>这样一来的降维处理，原来需要比较1375亿次，现在只需要比较3356万次即可得到结果，这样以来大大提升了计算效率。</p><p>根据网上测试数据显示，普通 PC 比较1000万次海明距离大约需要 300ms，也就是说3356万次（1375亿数据）只需花费3356/1000*0.3=1.0068s。那也就是说对于千亿级文本数据（如果每个文本1kb，约100TB数据）的相似度计算与去重工作我们最多只需要一秒的时间即可得出结果。</p><h3 id="四-HBase-存储设计"><a href="#四-HBase-存储设计" class="headerlink" title="四. HBase 存储设计"></a>四. HBase 存储设计</h3><p>饶了这么大一周，我们终于将需要讲明的理论知识给大家过了一遍。为了阐述的尽量清晰易懂，文中很多理论知识的理解借鉴了大量博主大牛的博客，原文链接已在文末附上，有不太明白的地方快快跪拜大牛们的博客吧，哈哈！</p><p>下面我们着重介绍一下 HBase 存储表的设计与实现。</p><p>基于上文我们可以大概知道，如果将64位指纹平分四份，海明距离取3，那么必有一段16位截取指纹的数据是相等的。而每一段16位截取指纹对应一个64位指纹集合，且该集合中的每个64位指纹必有一段16位截取指纹与该段16位截取指纹重合。我们可以简单表示(以8位非01指纹举例)为：</p><table><thead><tr><th>key</th><th>value(set)</th></tr></thead><tbody><tr><td>12</td><td>[12345678,12345679]</td></tr><tr><td>23</td><td>[12345678,12345679,23456789]</td></tr></tbody></table><p>那如果基于 HBase 去实现的话，我们大概对比三种可能的设计方案。</p><h4 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h4><p>以 16 位指纹作为 HBase 数据表的行键，将每一个与之可能相似的64位指纹作为 HBase 的列，列值存文章id值，即构建一张大宽表。如下表所示(以8位非01指纹举例)：</p><table><thead><tr><th>rowkey</th><th>column1</th><th>column2</th><th>column3</th><th>…</th></tr></thead></table><p>实际数据表可能是这个样子：</p><table><thead><tr><th>rowkey</th><th>12345678</th><th>32234567</th><th>23456789</th><th>12456789</th><th>…</th></tr></thead><tbody><tr><td>12</td><td>1102101</td><td></td><td></td><td>1102102</td><td>…</td></tr><tr><td>23</td><td></td><td>1102104</td><td>1102105</td><td></td><td>…</td></tr><tr><td>34</td><td>1102106</td><td></td><td></td><td></td><td>…</td></tr></tbody></table><p>那其实这样设计表的话该 HBase 表 Rowkey 的个数就是一个确定的数值：16个01数字随机组成的组合为2^16 个。也就是共2^16=65536行。 列的个数其实也是固定的，即2^64=184467440737亿万列。</p><p>此时，比如说我们比较56431234与库中所有文本的相似度，只需拉去rowkey in (56,43,12,34) 四行数据遍历每行列，由于 HBase 空值不进行存储，所有只会遍历存在值的列名。</p><p>由上文我们计算出1350亿数据如果平均分布的话每行大约有839万列，且不说我们的数据量可能远远大于千亿级别，也不说以64位字符串作为列名所占的存储空间有多大，单单千亿级数据量 HBase 每行就大约839万列，虽说HBase号称支持千万行百万列数据存储，但总归还是设计太不合理。数据不会理想化均匀分布，总列数高达184467440737亿万列也令人堪忧。</p><h4 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h4><p>以 16 位指纹与64位指纹拼接后作为 HBase 数据表的行键，该表只有一列，列值存文章id值，即构建一张大长表。如下表所示(以8位非01指纹举例)：</p><table><thead><tr><th>rowkey</th><th>id</th></tr></thead></table><p>实际数据表可能是这个样子：</p><table><thead><tr><th>rowkey</th><th>id</th></tr></thead><tbody><tr><td>12_12345678</td><td>1</td></tr><tr><td>34_12345678</td><td>1</td></tr><tr><td>56_12345678</td><td>1</td></tr><tr><td>78_12345678</td><td>1</td></tr><tr><td>34_22345678</td><td>2</td></tr><tr><td>23_12235678</td><td>3</td></tr></tbody></table><p>如此设计感觉要比第一种方法要好一些，每一篇文章会被存为四行。但同样有诸多缺点，一是 Rowkey 过长，二是即便我们通过某种转变设计解决了问题一，那获取数据时我们也只能将 Get 请求转为四个Scan并发扫描+StartEnKey 去扫描表获取数据。当然，如果想实现顺序扫描还可能存在热点问题。在存储上，也造成了数据大量冗余。</p><h4 id="方案三"><a href="#方案三" class="headerlink" title="方案三"></a>方案三</h4><p>在真实生产环境中，我们采取该方案来避免上述两个方案中出现的问题与不足。下面简单介绍一下（如果您有更好更优的方案，欢迎留言，先表示感谢！）</p><p>简言之呢，就是自己在 HBase 端维护了一个 Set 集合（协处理器），并以 Json 串进行存储，格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;64SimHash1&quot;:&quot;id1&quot;,</span><br><span class="line">    &quot;64SimHash2&quot;:&quot;id2&quot;,</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>基于公司存在多种主题类型的文本数据，且互相隔离，去重与相似度计算也是分主题进行，我们的 Rowkey 设计大致如下：</p><p>Rowkey = HashNumber_ContentType_16SimHash  (共24位)</p><ul><li>HashNumber： 为防热点，对表进行Hash预分区（64个预分区），占2个字符<br>计算公式如下：String.format(“%02x”, Math.abs(key.hashCode()) % 64)</li><li>ContentType ：内容主题类型，占4个字符</li><li>16SimHash： 16位 SimHash 截取指纹，由01组成</li></ul><p>表结构大致如下：</p><table><thead><tr><th>rowkey</th><th>si</th><th>s0</th><th>s1</th><th>s2</th><th>s3</th><th>…</th></tr></thead><tbody><tr><td>01_news_010101010101010101</td><td>value</td><td>1</td><td>Json 串</td><td></td><td></td><td>…</td></tr><tr><td>02_news_010101010101010110</td><td>value</td><td>2</td><td>Json 串</td><td>Json 串</td><td></td><td>…</td></tr><tr><td>03_news_100101010101010110</td><td>value</td><td>3</td><td>Json 串</td><td>Json 串</td><td>Json 串</td><td>…</td></tr><tr><td>01_xbbs_010101010101010101</td><td>value</td><td>1</td><td>Json 串</td><td></td><td></td><td>…</td></tr></tbody></table><p>si：客户端传递过来的欲存储的值，由64位 Simhash 与 Id 通过双下划线拼接而成，诸如 Simhash__Id 的形式。<br>s0：记录该行数据共有多少个 Set 集合，每一个 Set 集合存储10000个K-V对儿（约1MB）。<br>s1：第一个 Set 集合，Json 串存储，如果 Size &gt; 10000 ，之后来的数据将存入s2。<br>s2：以此类推。</p><p>当然最核心的部分是s1/s2/s3 中 Json 串中要排重。最简单的办法无非是每次存入数据前先将所有 Set 集合中的数据读到客户端，将欲存的数据与集合中所有数据比对后再次插入。这将带来大量往返IO开销，影响写性能。因此，我们在此引入了 HBase 协处理器技术来规避这个问题，即在服务端完成所有排重操作。大致代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line">package com.learn.share.scenarios.observers;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import com.google.gson.Gson;</span><br><span class="line">import com.google.gson.JsonObject;</span><br><span class="line">import org.apache.commons.lang.StringUtils;</span><br><span class="line">import org.apache.hadoop.hbase.Cell;</span><br><span class="line">import org.apache.hadoop.hbase.CellUtil;</span><br><span class="line">import org.apache.hadoop.hbase.CoprocessorEnvironment;</span><br><span class="line">import org.apache.hadoop.hbase.client.Durability;</span><br><span class="line">import org.apache.hadoop.hbase.client.Get;</span><br><span class="line">import org.apache.hadoop.hbase.client.Put;</span><br><span class="line">import org.apache.hadoop.hbase.client.Result;</span><br><span class="line">import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;</span><br><span class="line">import org.apache.hadoop.hbase.coprocessor.ObserverContext;</span><br><span class="line">import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;</span><br><span class="line">import org.apache.hadoop.hbase.regionserver.wal.WALEdit;</span><br><span class="line">import org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> *  基于协处理器构建百亿级文本去重系统</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class HBaseSimHashSetBuildSystem extends BaseRegionObserver &#123;</span><br><span class="line"></span><br><span class="line">    private Logger logger &#x3D; LoggerFactory.getLogger(HBaseSimHashSetBuildSystem.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void start(CoprocessorEnvironment e) throws IOException &#123;</span><br><span class="line">        logger.info(&quot;Coprocessor opration start...&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     *</span><br><span class="line">     * @param e</span><br><span class="line">     * @param put</span><br><span class="line">     * @param edit</span><br><span class="line">     * @param durability</span><br><span class="line">     * @throws IOException</span><br><span class="line">     *&#x2F;</span><br><span class="line">    @Override</span><br><span class="line">    public void prePut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException &#123;</span><br><span class="line">        &#x2F;&#x2F; test flag</span><br><span class="line">        logger.info(&quot;do something before Put Opration...&quot;);</span><br><span class="line"></span><br><span class="line">        List&lt;Cell&gt; cells &#x3D; put.get(Bytes.toBytes(&quot;f&quot;), Bytes.toBytes(&quot;si&quot;));</span><br><span class="line">        if (cells &#x3D;&#x3D; null || cells.size() &#x3D;&#x3D; 0) &#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        String simhash__itemid &#x3D; Bytes.toString(CellUtil.cloneValue(cells.get(0)));</span><br><span class="line">        if (StringUtils.isEmpty(simhash__itemid)||simhash__itemid.split(&quot;__&quot;).length!&#x3D;2)&#123;</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        String simhash &#x3D; simhash__itemid.trim().split(&quot;__&quot;)[0];</span><br><span class="line">        String itemid &#x3D; simhash__itemid.trim().split(&quot;__&quot;)[1];</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F; 获取Put Rowkey</span><br><span class="line">        byte[] row &#x3D; put.getRow();</span><br><span class="line">        &#x2F;&#x2F; 通过Rowkey构造Get对象</span><br><span class="line">        Get get &#x3D; new Get(row);</span><br><span class="line">        get.setMaxVersions(1);</span><br><span class="line">        get.addFamily(Bytes.toBytes(&quot;f&quot;));</span><br><span class="line">        Result result &#x3D; e.getEnvironment().getRegion().get(get);</span><br><span class="line">        Cell columnCell &#x3D; result.getColumnLatestCell(Bytes.toBytes(&quot;f&quot;), Bytes.toBytes(&quot;s0&quot;)); &#x2F;&#x2F; set size</span><br><span class="line">        if (columnCell &#x3D;&#x3D; null) &#123;</span><br><span class="line">            &#x2F;&#x2F; 第一次存储数据，将size初始化为1</span><br><span class="line">            logger.info(&quot;第一次存储数据，将size初始化为1&quot;);</span><br><span class="line"></span><br><span class="line">            JsonObject jsonObject &#x3D; new JsonObject();</span><br><span class="line">            jsonObject.addProperty(simhash,itemid);</span><br><span class="line">            Gson gson &#x3D; new Gson();</span><br><span class="line">            String json &#x3D; gson.toJson(jsonObject);</span><br><span class="line"></span><br><span class="line">            put.addColumn(Bytes.toBytes(&quot;f&quot;),Bytes.toBytes(&quot;s1&quot;), Bytes.toBytes(json)); &#x2F;&#x2F; json 数组</span><br><span class="line">            put.addColumn(Bytes.toBytes(&quot;f&quot;),Bytes.toBytes(&quot;s0&quot;), Bytes.toBytes(&quot;1&quot;));  &#x2F;&#x2F; 初始化</span><br><span class="line">        &#125;else &#123;</span><br><span class="line">            byte[] sizebyte &#x3D; CellUtil.cloneValue(columnCell);</span><br><span class="line">            int size &#x3D; Integer.parseInt(Bytes.toString(sizebyte));</span><br><span class="line">            logger.info(&quot;非第一次存储数据 ----&gt; Rowkey &#96;&quot;+Bytes.toString(row)+&quot;&#96; simhash set size is : &quot;+size +&quot;, the current value is : &quot;+simhash__itemid);</span><br><span class="line">            for (int i &#x3D; 1; i &lt;&#x3D; size; i++) &#123;</span><br><span class="line">                Cell cell1 &#x3D; result.getColumnLatestCell(Bytes.toBytes(&quot;f&quot;), Bytes.toBytes(&quot;s&quot;+i));</span><br><span class="line">                String jsonBefore &#x3D; Bytes.toString(CellUtil.cloneValue(cell1));</span><br><span class="line">                Gson gson &#x3D; new Gson();</span><br><span class="line">                JsonObject jsonObject &#x3D; gson.fromJson(jsonBefore, JsonObject.class);</span><br><span class="line">                int sizeBefore &#x3D; jsonObject.entrySet().size();</span><br><span class="line">                if(i&#x3D;&#x3D;size)&#123;</span><br><span class="line">                    if(!jsonObject.has(simhash))&#123;</span><br><span class="line">                        if (sizeBefore&#x3D;&#x3D;10000)&#123;</span><br><span class="line">                            JsonObject jsonone &#x3D; new JsonObject();</span><br><span class="line">                            jsonone.addProperty(simhash,itemid);</span><br><span class="line">                            String jsonstrone &#x3D; gson.toJson(jsonone);</span><br><span class="line">                            put.addColumn(Bytes.toBytes(&quot;f&quot;),Bytes.toBytes(&quot;s&quot;+(size+1)), Bytes.toBytes(jsonstrone)); &#x2F;&#x2F; json 数组</span><br><span class="line">                            put.addColumn(Bytes.toBytes(&quot;f&quot;),Bytes.toBytes(&quot;s0&quot;), Bytes.toBytes((size+1)+&quot;&quot;));  &#x2F;&#x2F; 初始化</span><br><span class="line">                        &#125;else &#123;</span><br><span class="line">                            jsonObject.addProperty(simhash,itemid);</span><br><span class="line">                            String jsonAfter &#x3D; gson.toJson(jsonObject);</span><br><span class="line">                            put.addColumn(Bytes.toBytes(&quot;f&quot;),Bytes.toBytes(&quot;s&quot;+size), Bytes.toBytes(jsonAfter)); &#x2F;&#x2F; json 数组</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;else &#123;</span><br><span class="line">                        return;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;else&#123;</span><br><span class="line">                    if(!jsonObject.has(simhash))&#123;</span><br><span class="line">                        continue;</span><br><span class="line">                    &#125;else &#123;</span><br><span class="line">                        return;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如此，当我们需要对某一文本指纹与库中数据进行比对时，只需一个Table.Get(List<Get>) 操作即可返回所有的数据，然后基于s0依次获取各个 Set 集合中的数据即可。</p><p>下面我们算一笔账，假设我们某主题类型数据依然有 2^37 条数据（1375亿数据），假设数据均匀分布，则每个16位（16个01数字随机组成的组合为2^16 个）倒排返回的最大数量为 (2^37) * 4 / (2^16) =8388608个候选结果，即每行约839个 Set 集合，每个Set 集合大约1M 的话，数据存储量也必然不会太大。</p><p>你如果有十种不同主题的数据，HBase 行数无非也才 (2^16)*10 = 655360 行而已。</p><p>如果再加上 Snappy 压缩呢？<br>如果再加上 Fast-Diff 编码呢？<br>如果再开启 Mob 对象存储呢？ 每个 Set 是不是可以存10万个键值对？每行只需90个 Set 集合。</p><p>也或许，如果数据量小的话，使用 Redis 是不是更好呢？</p><p>总之，优化完善和不完美的地方还很多，本文也就简单叙述到此，如果您有好的建议或是不同看法，欢迎留言哦！感恩~ 晚安各位~~</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://blog.csdn.net/u010454030/article/details/49102565" target="_blank" rel="noopener">1. https://blog.csdn.net/u010454030/article/details/49102565</a><br><a href="http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity2-html.html" target="_blank" rel="noopener">2. http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity2-html.html</a><br><a href="https://cloud.tencent.com/developer/news/218062" target="_blank" rel="noopener">3. https://cloud.tencent.com/developer/news/218062</a><br><a href="https://blog.csdn.net/qq_36142114/article/details/80540303" target="_blank" rel="noopener">4. https://blog.csdn.net/qq_36142114/article/details/80540303</a><br><a href="https://blog.csdn.net/u011467621/article/details/49685107" target="_blank" rel="noopener">5. https://blog.csdn.net/u011467621/article/details/49685107</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h3&gt;&lt;p&gt;随着大数据时代的到来，数据信息在给我们生活带来便利的同时，同样也给我们带来了一系列的考验与挑战。本文主要介绍了基于 Apache HBase 与 Google SimHash 等多种算法共同实现的一套支持百亿级文本数据相似度计算与快速去重系统的设计与实现。该方案在公司业务层面彻底解决了多主题海量文本数据所面临的存储与计算慢的问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HBase" scheme="http://yoursite.com/categories/HBase/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="2020" scheme="http://yoursite.com/tags/2020/"/>
    
      <category term="HBase" scheme="http://yoursite.com/tags/HBase/"/>
    
      <category term="SimHash" scheme="http://yoursite.com/tags/SimHash/"/>
    
      <category term="文本相似度计算" scheme="http://yoursite.com/tags/%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
</feed>
